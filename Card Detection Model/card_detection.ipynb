{"cells":[{"cell_type":"markdown","metadata":{"id":"K9GCMapA6LfO"},"source":["# Overview\n","This file is responsible for training the card detection aspect of our APS360 project. For this task, we are using a YOLOv8 model from the Ultralytics library and training it on our custom dataset.\n","\n","The file has been designed to work by simply selecting \"Run All\", and is organized into 5 main sections:\n","1.   Setup\n","2.   Dataset Loading\n","3.   Training\n","4.   Saving Models"]},{"cell_type":"markdown","metadata":{"id":"GYTWaeUr6z6J"},"source":["# Section 1: Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"fnaTaHNmW2NE","executionInfo":{"status":"ok","timestamp":1723601593310,"user_tz":240,"elapsed":11,"user":{"displayName":"Nathan Chin","userId":"15666622518481422567"}}},"outputs":[],"source":["# Options\n","# ... put any config stuff here ...\n","global PROJECT_FOLDER_PATH # comment in yours\n","PROJECT_FOLDER_PATH = '/content/gdrive/MyDrive/UofT/APS360/APS360 Project/Card Detection' # Nathan"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25673,"status":"ok","timestamp":1723601618975,"user":{"displayName":"Nathan Chin","userId":"15666622518481422567"},"user_tz":240},"id":"7jSiJjENW91v","outputId":"3c1a2e69-bbdb-4177-8ad5-fbc980ddfda6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["# Mount to Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":63314,"status":"ok","timestamp":1723601682283,"user":{"displayName":"Nathan Chin","userId":"15666622518481422567"},"user_tz":240},"id":"b5SW8gKIYM1R","outputId":"44cee5e6-9aac-4e69-fde8-3e17752776e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.2.77-py3-none-any.whl.metadata (41 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.1+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.1+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.0-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.1)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n","  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Downloading ultralytics-8.2.77-py3-none-any.whl (869 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.0/869.0 kB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Downloading ultralytics_thop-2.0.0-py3-none-any.whl (25 kB)\n","Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 ultralytics-8.2.77 ultralytics-thop-2.0.0\n"]}],"source":["# Install and import the Ultralytics library\n","%pip install ultralytics\n","from ultralytics import YOLO"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"BELTaWMOXAZ6","executionInfo":{"status":"ok","timestamp":1723601682284,"user_tz":240,"elapsed":21,"user":{"displayName":"Nathan Chin","userId":"15666622518481422567"}}},"outputs":[],"source":["# Import other relevant libraries\n","import os\n","import os.path as path\n","\n","import shutil"]},{"cell_type":"markdown","metadata":{"id":"KvMsaZ-G7Egw"},"source":["# Section 2: Dataset Loading\n","\n","This section contains code to prepare the dataset in the local runtime. This includes copying it from Google Drive and unzipping it to /content.\n","\n","Most of the work for data processing is in merging datasets and making a custom yaml file, so this section simply needs to unzip the prepared dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":79650,"status":"ok","timestamp":1723302911222,"user":{"displayName":"Nathan Chin","userId":"15666622518481422567"},"user_tz":-540},"id":"C3ixVLFcln5g","outputId":"d4fa8955-94c1-403a-e296-11c4800a892c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Unzipping dataset file to local runtime, this can take a while...\n"]}],"source":["print('Unzipping dataset file to local runtime, this can take a while...')\n","dataset_zip_path = path.join(PROJECT_FOLDER_PATH, 'dataset.zip')\n","dataset_folder_path = 'datasets'\n","\n","shutil.unpack_archive(dataset_zip_path, dataset_folder_path)"]},{"cell_type":"markdown","metadata":{"id":"4e7MLfJc7ucY"},"source":["# Section 3: Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4506862,"status":"ok","timestamp":1722921954516,"user":{"displayName":"Nathan Chin","userId":"15666622518481422567"},"user_tz":-540},"id":"pqZ-FTCKYl3p","outputId":"ccd1c057-fcd3-4271-c9df-ac39b45959be"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 6.25M/6.25M [00:00<00:00, 168MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["['594046321_jpg.rf.cc4a06633f9a3931d17a5f8ea1439b33.jpg', '144236322_jpg.rf.027ab44c35a8d442a3fdf99d8f99d421.jpg', '861294994_jpg.rf.abb02e22d2f027a4a9fdde7bae314288.jpg', '830780958_jpg.rf.c3e1933e25d76450f7539db2659de1e5.jpg', '303237274_jpg.rf.c41effb268a6a52aefa062e66311ff32.jpg', '212788355_jpg.rf.6f81ac2ac018b709795f323bffd3ef2d.jpg', '285154979_jpg.rf.9d4149e094311630949ead8d2a5c79bb.jpg', '860604500_jpg.rf.7217a3e41f34d91090702c092e15433f.jpg', '954068760_jpg.rf.9f46b7bcf190f693c66ce3e42518bf66.jpg', '629236490_jpg.rf.c119f8d2991dfff8ae3bafae051874b1.jpg']\n","Ultralytics YOLOv8.2.73 🚀 Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=datasets/dataset/data.yaml, epochs=5, time=None, patience=100, batch=64, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 755k/755k [00:00<00:00, 43.6MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Overriding model.yaml nc=80 with nc=52\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    761452  ultralytics.nn.modules.head.Detect           [52, [64, 128, 256]]          \n","Model summary: 225 layers, 3,020,988 parameters, 3,020,972 gradients, 8.2 GFLOPs\n","\n","Transferred 319/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/dataset/train/labels... 35203 images, 0 backgrounds, 0 corrupt: 100%|██████████| 35203/35203 [00:50<00:00, 690.75it/s] \n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/dataset/train/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/dataset/valid/labels... 6020 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6020/6020 [00:07<00:00, 776.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/dataset/valid/labels.cache\n","Plotting labels to runs/detect/train/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000179, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/detect/train\u001b[0m\n","Starting training for 5 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/5      9.45G      1.453      4.202       1.07         17        640: 100%|██████████| 551/551 [13:52<00:00,  1.51s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 48/48 [01:24<00:00,  1.75s/it]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       6020      23239      0.177      0.402      0.188      0.136\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        2/5      8.47G      1.165      2.362     0.9765         14        640: 100%|██████████| 551/551 [13:27<00:00,  1.47s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 48/48 [01:08<00:00,  1.43s/it]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       6020      23239      0.576      0.739      0.697      0.551\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        3/5      8.63G      1.098      1.611     0.9634          7        640: 100%|██████████| 551/551 [13:03<00:00,  1.42s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 48/48 [01:06<00:00,  1.38s/it]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       6020      23239      0.771      0.877      0.886      0.671\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        4/5      8.62G      1.044      1.254     0.9537         25        640: 100%|██████████| 551/551 [12:36<00:00,  1.37s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 48/48 [01:07<00:00,  1.41s/it]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       6020      23239      0.842      0.921      0.933      0.754\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        5/5      8.43G      1.007       1.08      0.948         12        640: 100%|██████████| 551/551 [12:40<00:00,  1.38s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 48/48 [01:04<00:00,  1.34s/it]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       6020      23239      0.873      0.938      0.953      0.798\n","\n","5 epochs completed in 1.199 hours.\n","Optimizer stripped from runs/detect/train/weights/last.pt, 6.3MB\n","Optimizer stripped from runs/detect/train/weights/best.pt, 6.3MB\n","\n","Validating runs/detect/train/weights/best.pt...\n","Ultralytics YOLOv8.2.73 🚀 Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 3,015,788 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 48/48 [01:29<00:00,  1.86s/it]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       6020      23239      0.874      0.937      0.953      0.798\n","                   10c        309        454      0.827      0.893      0.935      0.733\n","                   10d        312        451      0.842      0.913      0.947      0.756\n","                   10h        304        470      0.798      0.828      0.892      0.724\n","                   10s        277        403      0.823      0.903      0.918      0.747\n","                    2c        299        439       0.93      0.979      0.988      0.858\n","                    2d        284        424      0.936      0.958      0.984      0.833\n","                    2h        323        477      0.919      0.941      0.978       0.83\n","                    2s        294        436      0.957      0.952       0.99      0.849\n","                    3c        323        484      0.869      0.979      0.984      0.865\n","                    3d        273        395      0.935       0.91      0.969      0.834\n","                    3h        319        481      0.858      0.939      0.962      0.819\n","                    3s        333        500      0.918      0.939      0.975      0.844\n","                    4c        302        449      0.893      0.989      0.989      0.822\n","                    4d        276        401      0.884      0.965      0.977      0.835\n","                    4h        311        458      0.931      0.965      0.987      0.839\n","                    4s        307        440      0.912      0.982      0.985      0.841\n","                    5c        311        467      0.771      0.959      0.943      0.798\n","                    5d        312        465      0.832      0.951      0.945       0.79\n","                    5h        293        419      0.832      0.938      0.951      0.794\n","                    5s        308        438      0.802      0.963      0.957      0.816\n","                    6c        305        451      0.748      0.941      0.897      0.754\n","                    6d        316        461      0.788      0.905      0.914      0.759\n","                    6h        298        442      0.744      0.916      0.882      0.742\n","                    6s        285        418      0.778      0.899      0.905      0.775\n","                    7c        304        449      0.982      0.989      0.994      0.855\n","                    7d        313        478      0.935       0.97       0.99      0.829\n","                    7h        314        463       0.98      0.976      0.993      0.855\n","                    7s        310        452      0.962      0.989      0.993       0.86\n","                    8c        293        437      0.782      0.926      0.924      0.771\n","                    8d        293        432      0.798      0.863      0.893      0.747\n","                    8h        293        421      0.813      0.878      0.933      0.786\n","                    8s        329        491      0.752      0.853      0.889      0.753\n","                    9c        309        456      0.728      0.954      0.925      0.787\n","                    9d        289        415      0.749       0.87      0.891      0.757\n","                    9h        298        444      0.822      0.815      0.908       0.75\n","                    9s        297        417      0.774       0.93       0.93      0.774\n","                    Ac        315        469      0.804      0.889      0.908      0.745\n","                    Ad        300        440       0.77      0.835      0.862      0.714\n","                    Ah        314        449      0.803      0.811      0.887      0.719\n","                    As        324        466      0.738      0.906      0.875      0.719\n","                    Jc        281        402      0.988      0.995      0.993      0.829\n","                    Jd        286        430      0.962      0.984      0.991      0.815\n","                    Jh        290        429      0.974      0.979      0.994      0.804\n","                    Js        295        426      0.976      0.984      0.993      0.839\n","                    Kc        341        505      0.994      0.976      0.995       0.76\n","                    Kd        291        448      0.998      0.971      0.995      0.852\n","                    Kh        314        457      0.976       0.98      0.994      0.842\n","                    Ks        263        382      0.995      0.985      0.995      0.837\n","                    Qc        302        442      0.975      0.989      0.993      0.848\n","                    Qd        329        491      0.989      0.956      0.993      0.728\n","                    Qh        304        447      0.924      0.978       0.99       0.82\n","                    Qs        318        478      0.984       0.99      0.994      0.856\n","Speed: 0.2ms preprocess, 2.5ms inference, 0.0ms loss, 2.6ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train\u001b[0m\n"]}],"source":["model = YOLO('yolov8n.pt')\n","\n","print(os.listdir('datasets/dataset/valid/images')[:10])\n","\n","#yaml_path = path.join(PROJECT_FOLDER_PATH, 'dataset', 'formatted_data.yaml')\n","yaml_path = path.join('datasets', 'dataset', 'data.yaml')\n","results = model.train(data=yaml_path, epochs=5, batch=64)"]},{"cell_type":"markdown","metadata":{"id":"al3dguRQ7_9c"},"source":["# Section 4: Saving Models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":939,"status":"ok","timestamp":1722923592038,"user":{"displayName":"Nathan Chin","userId":"15666622518481422567"},"user_tz":-540},"id":"C53U9_-e8Kny","outputId":"c76b49c1-05c1-4778-a665-cdcb4359417b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Copying from runs/detect/train to /content/gdrive/MyDrive/UofT/APS360/APS360 Project/Card Detection/runs/train1...\n","Done!\n"]}],"source":["def save_run(src_folder, dest_folder):\n","    src_path = path.join('runs', 'detect', src_folder)\n","    dest_path = path.join(PROJECT_FOLDER_PATH, 'runs', dest_folder)\n","    print(f'Copying from {src_path} to {dest_path}...')\n","    shutil.copytree(src_path, dest_path)\n","    print('Done!')\n","\n","save_run('train', 'train1')"]},{"cell_type":"markdown","source":["# Section 5: Testing"],"metadata":{"id":"_3PeGTZGz-gw"}},{"cell_type":"code","source":["from ultralytics.utils.benchmarks import benchmark\n","\n","model_path = path.join(PROJECT_FOLDER_PATH, 'runs', 'train1', 'weights', 'best.pt')\n","yaml_path = path.join('datasets', 'dataset', 'data.yaml')\n","benchmark(model=model_path, data=yaml_path, imgsz=640, half=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iUresX6C0ACM","outputId":"efd7d965-6a2c-41ed-dc7a-6b7fa7d6e878","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /usr/local/lib/python3.10/dist-packages/ultralytics/assets/bus.jpg: 640x480 (no detections), 792.3ms\n","Speed: 24.8ms preprocess, 792.3ms inference, 25.0ms postprocess per image at shape (1, 3, 640, 480)\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 755k/755k [00:00<00:00, 119MB/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/dataset/valid/labels... 6020 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6020/6020 [00:02<00:00, 2117.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/dataset/valid/labels.cache\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6020/6020 [23:00<00:00,  4.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       6020      23239      0.874      0.938      0.953        0.8\n","Speed: 5.8ms preprocess, 211.7ms inference, 0.0ms loss, 1.0ms postprocess per image\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/gdrive/MyDrive/UofT/APS360/APS360 Project/Card Detection/runs/train1/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 56, 8400) (6.0 MB)\n","\n","\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.3.1+cu121...\n","\u001b[34m\u001b[1mTorchScript:\u001b[0m export success ✅ 2.3s, saved as '/content/gdrive/MyDrive/UofT/APS360/APS360 Project/Card Detection/runs/train1/weights/best.torchscript' (11.9 MB)\n","\n","Export complete (2.7s)\n","Results saved to \u001b[1m/content/gdrive/.shortcut-targets-by-id/1DsQfGNPcKchvFxCyS5CsfyAnvFYoU-0-/APS360 Project/Card Detection/runs/train1/weights\u001b[0m\n","Predict:         yolo predict task=detect model=/content/gdrive/MyDrive/UofT/APS360/APS360 Project/Card Detection/runs/train1/weights/best.torchscript imgsz=640  \n","Validate:        yolo val task=detect model=/content/gdrive/MyDrive/UofT/APS360/APS360 Project/Card Detection/runs/train1/weights/best.torchscript imgsz=640 data=datasets/dataset/data.yaml  \n","Visualize:       https://netron.app\n","Loading /content/gdrive/MyDrive/UofT/APS360/APS360 Project/Card Detection/runs/train1/weights/best.torchscript for TorchScript inference...\n","\n","image 1/1 /usr/local/lib/python3.10/dist-packages/ultralytics/assets/bus.jpg: 640x640 (no detections), 247.4ms\n","Speed: 3.2ms preprocess, 247.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n","Loading /content/gdrive/MyDrive/UofT/APS360/APS360 Project/Card Detection/runs/train1/weights/best.torchscript for TorchScript inference...\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/dataset/valid/labels.cache... 6020 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6020/6020 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6020/6020 [18:52<00:00,  5.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all       6020      23239      0.872      0.938      0.953      0.773\n","Speed: 1.5ms preprocess, 177.4ms inference, 0.0ms loss, 1.0ms postprocess per image\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/gdrive/MyDrive/UofT/APS360/APS360 Project/Card Detection/runs/train1/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 56, 8400) (6.0 MB)\n","\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnx>=1.12.0'] not found, attempting AutoUpdate...\n","Collecting onnx>=1.12.0\n","  Downloading onnx-1.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.12.0) (1.26.4)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.12.0) (3.20.3)\n","Downloading onnx-1.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 15.9/15.9 MB 281.1 MB/s eta 0:00:00\n","Installing collected packages: onnx\n","Successfully installed onnx-1.16.2\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 6.7s, installed 1 package: ['onnx>=1.12.0']\n","\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n","\n","\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.2 opset 17...\n","\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 7.9s, saved as '/content/gdrive/MyDrive/UofT/APS360/APS360 Project/Card Detection/runs/train1/weights/best.onnx' (11.7 MB)\n","\n","Export complete (8.3s)\n","Results saved to \u001b[1m/content/gdrive/.shortcut-targets-by-id/1DsQfGNPcKchvFxCyS5CsfyAnvFYoU-0-/APS360 Project/Card Detection/runs/train1/weights\u001b[0m\n","Predict:         yolo predict task=detect model=/content/gdrive/MyDrive/UofT/APS360/APS360 Project/Card Detection/runs/train1/weights/best.onnx imgsz=640  \n","Validate:        yolo val task=detect model=/content/gdrive/MyDrive/UofT/APS360/APS360 Project/Card Detection/runs/train1/weights/best.onnx imgsz=640 data=datasets/dataset/data.yaml  \n","Visualize:       https://netron.app\n","Loading /content/gdrive/MyDrive/UofT/APS360/APS360 Project/Card Detection/runs/train1/weights/best.onnx for ONNX Runtime inference...\n","\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnxruntime'] not found, attempting AutoUpdate...\n","Collecting onnxruntime\n","  Downloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n","Collecting coloredlogs (from onnxruntime)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n","Requirement already satisfied: numpy<2.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.26.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.1)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.13.1)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n","Downloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.8/6.8 MB 182.2 MB/s eta 0:00:00\n","Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 236.0 MB/s eta 0:00:00\n","Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 243.6 MB/s eta 0:00:00\n","Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n","Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.18.1\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 3.4s, installed 1 package: ['onnxruntime']\n","\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n","\n","image 1/1 /usr/local/lib/python3.10/dist-packages/ultralytics/assets/bus.jpg: 640x640 (no detections), 157.1ms\n","Speed: 4.9ms preprocess, 157.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n","Loading /content/gdrive/MyDrive/UofT/APS360/APS360 Project/Card Detection/runs/train1/weights/best.onnx for ONNX Runtime inference...\n","Setting batch=1 input of shape (1, 3, 640, 640)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/dataset/valid/labels.cache... 6020 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6020/6020 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  59%|█████▊    | 3533/6020 [10:11<10:06,  4.10it/s]"]}]},{"cell_type":"code","source":["# get paths\n","model_path = path.join(PROJECT_FOLDER_PATH, 'runs', 'train1', 'weights', 'best.pt')\n","model = YOLO(model_path)"],"metadata":{"collapsed":true,"id":"F93M6u6FqzdH","executionInfo":{"status":"ok","timestamp":1723602565731,"user_tz":240,"elapsed":374,"user":{"displayName":"Nathan Chin","userId":"15666622518481422567"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# predict\n","image_path = path.join(PROJECT_FOLDER_PATH, 'media', 'screenie_cropped.png')\n","results = model.predict(image_path, save=True)\n","\n","# display and save\n","save_path = path.join(PROJECT_FOLDER_PATH, 'media', 'screenie_cropped_results.png')\n","for result in results:\n","    result.plot()\n","    result.save(filename=save_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uBuSyZLJtV9c","executionInfo":{"status":"ok","timestamp":1723602876835,"user_tz":240,"elapsed":377,"user":{"displayName":"Nathan Chin","userId":"15666622518481422567"}},"outputId":"69032a21-5b65-489e-b3cd-28c8a8d96270"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/gdrive/MyDrive/UofT/APS360/APS360 Project/Card Detection/media/screenie_cropped.png: 576x640 2 10ds, 1 2s, 3 9cs, 2 Qds, 1 Qh, 7.3ms\n","Speed: 2.4ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n","Results saved to \u001b[1mruns/detect/predict2\u001b[0m\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyMz3unsFCA8oSJ5DqtRu/lb"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}